# -*- coding: utf-8 -*-


Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gzLp48IpA7_uxTH4mliI54LhUcAiBaVo

1.load the data
"""

import pandas as pd
import numpy as np
import nltk
sentiment = pd.read_csv('sentiment-training.csv', header =None)
sentiment.columns = ['review','class']
sentiment.head()



"""2.Clean the data"""

import re
from nltk.tokenize import word_tokenize, sent_tokenize
sentiment['processed review'] = sentiment['review'].map(lambda x: x.lower())
##sentiment.head()
def clean_numbers(text):
    return re.sub('[0-9]+', '', text)
sentiment['processed review'] = sentiment['processed review'].apply(lambda x: clean_numbers(x))

reviews = list(sentiment['processed review'])
print(len(reviews))
sentiment.head()
#sentiment['processed review'].head()

"""3.tokenize """

import nltk
nltk.download('punkt')
from nltk.tokenize import word_tokenize, sent_tokenize
sentiment['tokenized']  = sentiment['processed review'].map(lambda x: word_tokenize(x))
sentiment.head()



"""3.1 stemming """

from nltk.stem.lancaster import LancasterStemmer
lancaster_stemmer = LancasterStemmer()
st= nltk.PorterStemmer()
def stem(wlist):
    text = [st.stem(word) for word in wlist]
    return wlist
sentiment['tokenized']= sentiment['tokenized'].apply(lambda x: stem(x))
sentiment['tokenized'].head()

"""4.Construct features using TF_IDF




"""

from sklearn.feature_extraction.text import TfidfVectorizer

import numpy as np 

# specify vectorizer parameters 
tfidf_vectorizer = TfidfVectorizer(max_features=600, stop_words='english', use_idf=True, ngram_range=(1,2))
#tfidf_matrix = tfidf_vectorizer.fit_transform(reviews).toarray()

#print(tfidf_vectorizer.get_feature_names_out())
#print(tfidf_matrix[2])

#print(tfidf_matrix.shape)

import nltk

"""5. split training and testing data"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report
from sklearn.model_selection import KFold, cross_val_score

sentiment['tokenized'] = sentiment['tokenized'].map(lambda x: ' '.join(x))
x = sentiment['tokenized']
x = tfidf_vectorizer.fit_transform(x) # transform x into numerical data
y = sentiment['class']

x.shape
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.1, random_state = 0)
x_train.shape, x_test.shape #1599 rows will used for training and 400 rows will be used for testing

"""5. training model"""



k = 10
kf = KFold(n_splits=k, random_state=None)
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=40)
result = cross_val_score(model , x, y, cv = kf)
result.mean()



